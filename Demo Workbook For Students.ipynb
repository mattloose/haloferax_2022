{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b538265b",
   "metadata": {},
   "source": [
    "# Introduction\n",
    "\n",
    "As before we need to set up our notebook with the relevant code for analysis of our data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cbfc74b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:100% !important; }</style>\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fd3734e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#This hides some warnings that we might want to look at one day if our code doesn't work!\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore', category=DeprecationWarning)\n",
    "\n",
    "#These are various graph plotting and data processing tools we may use.\n",
    "from bokeh.io import output_notebook\n",
    "from bokeh.plotting import figure, show\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "#This is a nice plotting library that will also do some pretty graphics for us.\n",
    "import aplanat\n",
    "from aplanat import points\n",
    "from aplanat import graphics\n",
    "from aplanat.hist import histogram\n",
    "from aplanat.lines import steps\n",
    "from bokeh.layouts import gridplot\n",
    "\n",
    "\n",
    "#A library to manipulate sam files\n",
    "import pysam\n",
    "#This hides some warnings that we might want to look at one day if our code doesn't work!\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore', category=DeprecationWarning)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1937d11",
   "metadata": {},
   "source": [
    "## Required Files\n",
    "\n",
    "We are going to need some reference files to map our data too. We will use two references. The first (called \"reference\") is the Hmed an Hvol genomes combined. The seconde (called \"reference2\") is just the Hmed genome sequence. These are set up in the cell below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "387d48ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "reference = \"~/student_projects_2022/data/refs/merged_refs.fasta\"\n",
    "reference_index = \"~/student_projects_2022/data/refs/merged_refs.fasta.fai\"\n",
    "\n",
    "reference2 = \"~/student_projects_2022/data/refs/Hmed_Chr_CP001868.2.fasta\"\n",
    "reference2_index = \"~/student_projects_2022/data/refs/Hmed_Chr_CP001868.2.fasta.fai\"\n",
    "\n",
    "reference3 = \"~/student_projects_2022/data/refs/Hvol_Chr_NC_013967.1.fasta\"\n",
    "reference3_index = \"~/student_projects_2022/data/refs/Hvol_Chr_NC_013967.1.fasta.fai\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "890acbb7",
   "metadata": {},
   "source": [
    "## Data Summaries and Analysis\n",
    "\n",
    "We need to know a little bit about the data set that you have obtained for your sample.\n",
    "\n",
    "First you need to tell the computer which barcode you want to look at. We will store this in a variable called \"barcode\".\n",
    "\n",
    "Fill in the value of your barcode in the cell below. This needs to be a two digit number - e.g. one of:\n",
    "\n",
    "01\n",
    "02\n",
    "03\n",
    "04\n",
    "05\n",
    "06\n",
    "07\n",
    "08\n",
    "09\n",
    "10\n",
    "11\n",
    "12\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d214e413",
   "metadata": {},
   "outputs": [],
   "source": [
    "barcode=\"07\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64cc4afe",
   "metadata": {},
   "source": [
    "We have pregrouped the data in the folder so we can now find your reads by creating a new variable called reads like this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88b83258",
   "metadata": {},
   "outputs": [],
   "source": [
    "reads = f\"~/student_projects_2022/data/ic_131/Haloferax_clean_RBK004ori/20221104_1529_X2_FAV40358_9bd50a0f/fastq_*/barcode{barcode}/*.fastq.gz\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d62d3c3",
   "metadata": {},
   "source": [
    "We also need to create a few output file names that we can use in the rest of the code.\n",
    "We are going to map our reads in a few different ways. Firstly we will map them to both reference genomes and then each genome individually."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cebacf67",
   "metadata": {},
   "outputs": [],
   "source": [
    "sort_barcode_bam = f\"sorted_{barcode}_out.bam\"\n",
    "sort_barcode_bam_hmed = f\"sorted_{barcode}_out_hmed.bam\"\n",
    "sort_barcode_bam_hvol = f\"sorted_{barcode}_out_hvol.bam\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c0aa8a7",
   "metadata": {},
   "source": [
    "### Using LAST\n",
    "\n",
    "As we saw last time, LAST is more useful mapper for us than minimap2 for this experiment. We therefore need to make our last reference database for each of our genomes.\n",
    "\n",
    "This step is quite slow. Therefore we have precomputed these and instead we will just load the references. The first three lines would be used to generate the references usually."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e58a3fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!lastdb -uNEAR ~/student_projects_2022/data/refs/halodb $reference\n",
    "#!lastdb -uNEAR ~/student_projects_2022/data/refs/hmeddb $reference2\n",
    "#!lastdb -uNEAR ~/student_projects_2022/data/refs/hvoldb $reference3\n",
    "halodb=\"~/student_projects_2022/data/refs/halodb\"\n",
    "hmeddb=\"~/student_projects_2022/data/refs/hmeddb\"\n",
    "hvoldb=\"~/student_projects_2022/data/refs/hvoldb\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7119c43",
   "metadata": {},
   "source": [
    "### What are our databases?\n",
    "\n",
    "halodb is both reference genomes.\n",
    "\n",
    "hmeddb is just the H med reference.\n",
    "\n",
    "hvoldb is just the H vol reference."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d995446",
   "metadata": {},
   "source": [
    "### Training Last\n",
    "The last aligner can be run with lots of different parameters - choosing the correct ones is challenging. So the authors of the aligner have provided a way for us to be able to work out the parameters with training.\n",
    "\n",
    "The cell below will train the last aligner using your reads for each of the two databases we need to look at. This bit is slow if you have a lot of data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0d563ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "!last-train -P 8 -Q1 $halodb $reads > train.out\n",
    "!last-train -P 8 -Q1 $hmeddb $reads > train_hmed.out\n",
    "!last-train -P 8 -Q1 $hvoldb $reads > train_hvol.out"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24979d69",
   "metadata": {},
   "source": [
    "A problem with the data we are looking at here is that we expect some of our reads to map to both genomes - these are the reads we are really interested in! These reads are the \"recombinants\". To find these we are going to use a tool called last-split. last-split finds the optimal mapping for each section of a read.\n",
    "\n",
    "First off we will map our reads to both genomes using last and have a look at the output.\n",
    "\n",
    "This command does a lot of things!\n",
    "\n",
    "lastal. It aligns the reads to the halodb using the training information we generated earlier. It passes the output of this to the next program through a 'pipe' - the 'pipe' is the \"|\" character.\n",
    "last-split - splits the outputs it gets from the aligner into the best ones for each genome and then pipes it's output to:\n",
    "maf-convert - this program converts the maf output file from last into a samtools file which is then piped into:\n",
    "samtools view - this is tricky. This samtools command is adding essential information about the reference into the bam file which is then piped into:\n",
    "samtools sort - we've used this before - we want to sort our alignments along the genome.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bcb00ad",
   "metadata": {},
   "source": [
    "## Aligning to both genomes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f2fd799",
   "metadata": {},
   "outputs": [],
   "source": [
    "!lastal -P 8 --split -p train.out $halodb $reads | last-split | maf-convert sam - | samtools view -bt $reference_index | samtools sort -@16 -o $sort_barcode_bam"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "453bd9fc",
   "metadata": {},
   "source": [
    "Finally we need to index our bam file so we can analyse it further."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea6eeb33",
   "metadata": {},
   "outputs": [],
   "source": [
    "!samtools index $sort_barcode_bam"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91092b69",
   "metadata": {},
   "source": [
    "## Aligning to just the med genome."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d6f6e0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "!lastal -P 8 -p train_hmed.out $hmeddb $reads | last-split | maf-convert sam - | samtools view -bt $reference2_index | samtools sort -@16 -o $sort_barcode_bam_hmed"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82a76136",
   "metadata": {},
   "source": [
    "Finally we need to index our bam file so we can analyse it further."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33529bf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "!samtools index $sort_barcode_bam_hmed"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2c847b7",
   "metadata": {},
   "source": [
    "## Aligning to just the H. vol genome."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecc6d8c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "!lastal -P 8 -p train_hvol.out $hvoldb $reads | last-split | maf-convert sam - | samtools view -bt $reference3_index | samtools sort -@16 -o $sort_barcode_bam_hvol"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f57a176",
   "metadata": {},
   "source": [
    "Finally we need to index our bam file so we can analyse it further."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad69167c",
   "metadata": {},
   "outputs": [],
   "source": [
    "!samtools index $sort_barcode_bam_hvol"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76715834",
   "metadata": {},
   "source": [
    "Having done all of this, we should be able to generate some stats about our data!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e942a4d4",
   "metadata": {},
   "source": [
    "### Statistics for mapping to both genomes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "139889c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# run the alignment summarizer program\n",
    "!stats_from_bam $sort_barcode_bam > sorted.reads_reference.bam.stats\n",
    "\n",
    "\n",
    "df = pd.read_csv(\"sorted.reads_reference.bam.stats\", sep=\"\\t\")\n",
    "\n",
    "p1 = histogram(\n",
    "    [df['read_length']], title=\"Read lengths\",\n",
    "    x_axis_label=\"read length / bases\", y_axis_label=\"count\",bins=100)\n",
    "p1.xaxis.formatter.use_scientific = False\n",
    "p2 = histogram(\n",
    "    [df['acc']], title=\"Read accuracy\",\n",
    "    x_axis_label=\"% accuracy\", y_axis_label=\"count\",bins=100)\n",
    "aplanat.show(gridplot((p1, p2), ncols=2))\n",
    "\n",
    "\n",
    "summary = graphics.InfoGraphItems()\n",
    "summary.append(label='Total reads', value=len(df.name.unique()), icon='angle-up', unit='')\n",
    "summary.append('Total yield', df.drop_duplicates(subset=[\"name\"], keep='first').read_length.sum(), 'signal', 'b')\n",
    "summary.append('Mean read length', df.drop_duplicates(subset=[\"name\"], keep='first').read_length.sum()/len(df.name.unique()), 'align-center', 'b')\n",
    "summary.append('Mean read identity', df.iden.mean(), 'check')\n",
    "summary.append('Mean read accuracy', df.acc.mean(), 'check')\n",
    "plot = graphics.infographic(summary.values())\n",
    "aplanat.show(plot, background='#f4f4f4')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6877ab0",
   "metadata": {},
   "source": [
    "### Statistics for mapping just to H Vol."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c715b2b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# run the alignment summarizer program\n",
    "!stats_from_bam $sort_barcode_bam_hvol > sorted.reads_reference_hvol.bam.stats\n",
    "\n",
    "\n",
    "df = pd.read_csv(\"sorted.reads_reference_hvol.bam.stats\", sep=\"\\t\")\n",
    "\n",
    "p1 = histogram(\n",
    "    [df['read_length']], title=\"Read lengths\",\n",
    "    x_axis_label=\"read length / bases\", y_axis_label=\"count\",bins=100)\n",
    "p1.xaxis.formatter.use_scientific = False\n",
    "p2 = histogram(\n",
    "    [df['acc']], title=\"Read accuracy\",\n",
    "    x_axis_label=\"% accuracy\", y_axis_label=\"count\",bins=100)\n",
    "aplanat.show(gridplot((p1, p2), ncols=2))\n",
    "\n",
    "\n",
    "summary = graphics.InfoGraphItems()\n",
    "summary.append(label='Total reads', value=len(df.name.unique()), icon='angle-up', unit='')\n",
    "summary.append('Total yield', df.drop_duplicates(subset=[\"name\"], keep='first').read_length.sum(), 'signal', 'b')\n",
    "summary.append('Mean read length', df.drop_duplicates(subset=[\"name\"], keep='first').read_length.sum()/len(df.name.unique()), 'align-center', 'b')\n",
    "summary.append('Mean read identity', df.iden.mean(), 'check')\n",
    "summary.append('Mean read accuracy', df.acc.mean(), 'check')\n",
    "plot = graphics.infographic(summary.values())\n",
    "aplanat.show(plot, background='#f4f4f4')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47c95110",
   "metadata": {},
   "source": [
    "Why has this changed?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd52a867",
   "metadata": {},
   "source": [
    "### Mapping just to H Med Genome."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "742be711",
   "metadata": {},
   "outputs": [],
   "source": [
    "# run the alignment summarizer program\n",
    "!stats_from_bam $sort_barcode_bam_hmed > sorted.reads_reference_hmed.bam.stats\n",
    "\n",
    "\n",
    "df = pd.read_csv(\"sorted.reads_reference_hmed.bam.stats\", sep=\"\\t\")\n",
    "\n",
    "p1 = histogram(\n",
    "    [df['read_length']], title=\"Read lengths\",\n",
    "    x_axis_label=\"read length / bases\", y_axis_label=\"count\",bins=100)\n",
    "p1.xaxis.formatter.use_scientific = False\n",
    "p2 = histogram(\n",
    "    [df['acc']], title=\"Read accuracy\",\n",
    "    x_axis_label=\"% accuracy\", y_axis_label=\"count\",bins=100)\n",
    "aplanat.show(gridplot((p1, p2), ncols=2))\n",
    "\n",
    "\n",
    "summary = graphics.InfoGraphItems()\n",
    "summary.append(label='Total reads', value=len(df.name.unique()), icon='angle-up', unit='')\n",
    "summary.append('Total yield', df.drop_duplicates(subset=[\"name\"], keep='first').read_length.sum(), 'signal', 'b')\n",
    "summary.append('Mean read length', df.drop_duplicates(subset=[\"name\"], keep='first').read_length.sum()/len(df.name.unique()), 'align-center', 'b')\n",
    "summary.append('Mean read identity', df.iden.mean(), 'check')\n",
    "summary.append('Mean read accuracy', df.acc.mean(), 'check')\n",
    "plot = graphics.infographic(summary.values())\n",
    "aplanat.show(plot, background='#f4f4f4')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bea63161",
   "metadata": {},
   "source": [
    "## What now?\n",
    "\n",
    "Again - why has this changed?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "104a6de5",
   "metadata": {},
   "source": [
    "# Do we have recombinants?\n",
    "Now we are going to look at coverage with the tool mosdepth to see if we can see our recombinants."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1649cc10",
   "metadata": {},
   "outputs": [],
   "source": [
    "barcode_cov = f\"last_barcode{barcode}_cov\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef0653c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "!mosdepth -n --fast-mode --by 100 $barcode_cov $sort_barcode_bam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d7c2bd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "cumulative_depth = pd.read_csv(\n",
    "    f'{barcode_cov}.mosdepth.region.dist.txt', sep='\\t',\n",
    "    names=['ref', 'depth', 'proportion'])\n",
    "\n",
    "binned_depth = pd.read_csv(\n",
    "    f'{barcode_cov}.regions.bed.gz', sep='\\t',\n",
    "    names=['ref', 'start', 'end', 'depth'])\n",
    "\n",
    "def make_coverage_plot(cumulative_depth, binned_depth):\n",
    "    # Plot the proportion of the genome at coverage levels\n",
    "    p1 = steps(\n",
    "        [cumulative_depth[cumulative_depth['ref'].eq(binned_depth['ref'].unique()[0])]['depth']],\n",
    "        [cumulative_depth[cumulative_depth['ref'].eq(binned_depth['ref'].unique()[0])]['proportion']],\n",
    "        colors=['darkolivegreen'],\n",
    "        x_axis_label='Depth of coverage',\n",
    "        y_axis_label='Proportion of genome at coverage',\n",
    "        title=binned_depth['ref'].unique()[0])\n",
    "    \n",
    "    # Plot the binned coverage levels across the genome\n",
    "    \n",
    "    p2 = steps(\n",
    "        [binned_depth[binned_depth['ref'].eq(binned_depth['ref'].unique()[0])]['start']],\n",
    "        [binned_depth[binned_depth['ref'].eq(binned_depth['ref'].unique()[0])]['depth']],\n",
    "        colors=['darkolivegreen'],\n",
    "        x_axis_label='Position along reference',\n",
    "        y_axis_label='sequencing depth / bases',\n",
    "        title=binned_depth['ref'].unique()[0])\n",
    "    p2.xaxis.formatter.use_scientific = False\n",
    "    \n",
    "    p3 = steps(\n",
    "        [cumulative_depth[cumulative_depth['ref'].eq(binned_depth['ref'].unique()[1])]['depth']],\n",
    "        [cumulative_depth[cumulative_depth['ref'].eq(binned_depth['ref'].unique()[1])]['proportion']],\n",
    "        colors=['darkblue'],\n",
    "        x_axis_label='Depth of coverage',\n",
    "        y_axis_label='Proportion of genome at coverage',\n",
    "        title=binned_depth['ref'].unique()[1])\n",
    "\n",
    "    \n",
    "    # Plot the binned coverage levels across the genome\n",
    "    \n",
    "    p4 = steps(\n",
    "        [binned_depth[binned_depth['ref'].eq(binned_depth['ref'].unique()[1])]['start']],\n",
    "        [binned_depth[binned_depth['ref'].eq(binned_depth['ref'].unique()[1])]['depth']],\n",
    "        colors=['darkblue'],\n",
    "        x_axis_label='Position along reference',\n",
    "        y_axis_label='sequencing depth / bases',\n",
    "        title=binned_depth['ref'].unique()[1])\n",
    "    p4.xaxis.formatter.use_scientific = False\n",
    "    return gridplot((p1, p2,p3,p4), ncols=2)\n",
    "\n",
    "aplanat.show(make_coverage_plot(cumulative_depth, binned_depth), background=\"#ffffff\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7273a60f",
   "metadata": {},
   "source": [
    "# Think\n",
    "\n",
    "Why does our coverage look different here? What are the spikes in coverage? Why are the results not as good as our simulated data?\n",
    "\n",
    "## Viewing the alignments\n",
    "\n",
    "Now we will use IGV to look at the alignments in more detail.\n",
    "\n",
    "Run the code below and use it to highlight regions of the genome and - specifically - the genes where the recombination events are occurring.\n",
    "\n",
    "You can view two regions of a genome at once by entering the coordinates like this:\n",
    "\n",
    "\"CP001868.2:480,000-490,000 CP001868.2:850,000-860,000\" \n",
    "\n",
    "or if you want to be really flash:\n",
    "\n",
    "\"CP001868.2:405,000-415,000 NC_013967.1:420,000-430,000 NC_013967.1:785000-795000 CP001868.2:800,000-805,000\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3e25d03",
   "metadata": {},
   "outputs": [],
   "source": [
    "from igv_jupyterlab import IGV\n",
    "import os\n",
    "user = os.getenv('JUPYTERHUB_USER')\n",
    "\n",
    "url=f\"http://10.157.200.14/user/{user}/tree/UnderGradProjectTest/\"\n",
    "bams={'results':sort_barcode_bam}\n",
    "track_list=[\n",
    "            {\"name\": \"HMerge\",\n",
    "                \"url\": url+\"data/refs/merge.gff3\",\n",
    "                \"format\": \"gff3\",\n",
    "                \"type\": \"annotation\",\n",
    "                \"displayMode\": \"expanded\",\n",
    "                \"height\":120,\n",
    "                \"indexed\": False }\n",
    "]\n",
    "colors=['orange','green','gray']\n",
    "i=0\n",
    "for b in bams:\n",
    "    d = {\"name\": b,\n",
    "        \"url\":url+bams[b],\n",
    "        \"type\": \"alignment\",\n",
    "         #\"displayMode\":\"SQUISHED\",\n",
    "         \"height\":800,\n",
    "         \"removable\":True,\n",
    "         #\"color\":colors[i],\n",
    "        \"indexed\": True }\n",
    "    track_list.append(d)\n",
    "    i+=1\n",
    "    \n",
    "genome = IGV.create_genome(\n",
    "    name=\"merged_refs\",   \n",
    "    fasta_url=url+'data/refs/merged_refs.fasta',\n",
    "    index_url=url+ 'data/refs/merged_refs.fasta.fai',\n",
    "    tracks=track_list\n",
    ")\n",
    "\n",
    "#create the widget\n",
    "igv = IGV(genome=genome)\n",
    "\n",
    "\n",
    "display(igv)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec240595",
   "metadata": {},
   "source": [
    "## List Your Identified Genes\n",
    "\n",
    "You should find four genes - one at each end of the recombination event for each genome. We will call these CP_Left, CP_Right, NC_Left and NC_Right.\n",
    "\n",
    "Complete the cell below with the relevant information. You must leave in the quotes and copy the gene names exactly up to the first full stop. So HFX_0896.mRNA.0 will become \"HFX_0896\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32e3e98a",
   "metadata": {},
   "outputs": [],
   "source": [
    "CP_Left=\"HFX_0440\"\n",
    "CP_Right=\"HFX_0844\"\n",
    "NC_Left=\"HVO_0476\"\n",
    "NC_Right=\"HVO_0869\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61a9a6e8",
   "metadata": {},
   "source": [
    "## What are these genes?\n",
    "\n",
    "To find what these genes are, we need to look for them in the annotation files for the genomes. We can find this information from the annotation file used to label the IGV plot above.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c061ce8",
   "metadata": {},
   "outputs": [],
   "source": [
    "!grep $CP_Left ~/student_projects_2022/data/refs/merge.gff3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70d34a1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "!grep $CP_Right ~/student_projects_2022/data/refs/merge.gff3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "577642a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "!grep $NC_Left ~/student_projects_2022/data/refs/merge.gff3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc0d0504",
   "metadata": {},
   "outputs": [],
   "source": [
    "!grep $NC_Right ~/student_projects_2022/data/refs/merge.gff3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "413e5860",
   "metadata": {},
   "source": [
    "For some of these files we can see what they are by looking at the product name. Others are hypothetical proteins. To identify the hypothetical proteins, we need to get the sequence so we can analyse them.\n",
    "\n",
    "To do this, we will use a tool called GFF3Toolkit.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3074c492",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "!gff3_to_fasta -g ~/student_projects_2022/data/refs/merge.gff3 -f $reference -st cds -o test_genes -d complex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46ed5761",
   "metadata": {},
   "outputs": [],
   "source": [
    "!grep -A1 $CP_Right ~/haloferax_2022/test_genes_cds.fa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d122c46e",
   "metadata": {},
   "outputs": [],
   "source": [
    "!grep -A1 $NC_Right ~/haloferax_2022/test_genes_cds.fa"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ee261da",
   "metadata": {},
   "source": [
    "## Now lets look at the alignment with respect to just one genome.\n",
    "\n",
    "Again we will use IGV but we will just look at the reads with respect to one genome.\n",
    "\n",
    "### Hmed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "145ebd82",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"Hmed_Chr_CP001868.2:405,000-415,000 Hmed_Chr_CP001868.2:800,000-805,000\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0f264c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from igv_jupyterlab import IGV\n",
    "import os\n",
    "user = os.getenv('JUPYTERHUB_USER')\n",
    "\n",
    "url=f\"http://10.157.200.14/user/{user}/tree/UnderGradProjectTest/\"\n",
    "bams={'results':sort_barcode_bam_hmed}\n",
    "track_list=[\n",
    "            {\"name\": \"HMerge\",\n",
    "                \"url\": url+\"data/refs/Hmed.gff3\",\n",
    "                \"format\": \"gff3\",\n",
    "                \"type\": \"annotation\",\n",
    "                \"displayMode\": \"expanded\",\n",
    "                \"height\":120,\n",
    "                \"indexed\": False }\n",
    "]\n",
    "colors=['orange','green','gray']\n",
    "i=0\n",
    "for b in bams:\n",
    "    d = {\"name\": b,\n",
    "        \"url\":url+bams[b],\n",
    "        \"type\": \"alignment\",\n",
    "         #\"displayMode\":\"SQUISHED\",\n",
    "         \"height\":800,\n",
    "         \"removable\":True,\n",
    "         #\"color\":colors[i],\n",
    "        \"indexed\": True }\n",
    "    track_list.append(d)\n",
    "    i+=1\n",
    "    \n",
    "genome = IGV.create_genome(\n",
    "    name=\"Hmed\",   \n",
    "    fasta_url=url+'data/refs/Hmed_Chr_CP001868.2.fasta',\n",
    "    index_url=url+ 'data/refs/Hmed_Chr_CP001868.2.fasta.fai',\n",
    "    tracks=track_list\n",
    ")\n",
    "\n",
    "#create the widget\n",
    "igv = IGV(genome=genome)\n",
    "\n",
    "\n",
    "display(igv)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a06942cf",
   "metadata": {},
   "source": [
    "### Hvol"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc19d8c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"Hvol_Chr_NC_013967.1:420,000-430,000 Hvol_Chr_NC_013967.1:785000-795000\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba4d7276",
   "metadata": {},
   "outputs": [],
   "source": [
    "from igv_jupyterlab import IGV\n",
    "import os\n",
    "user = os.getenv('JUPYTERHUB_USER')\n",
    "\n",
    "url=f\"http://10.157.200.14/user/{user}/tree/UnderGradProjectTest/\"\n",
    "bams={'results':sort_barcode_bam_hvol}\n",
    "track_list=[\n",
    "            {\"name\": \"HMerge\",\n",
    "                \"url\": url+\"data/refs/Hvol.gff3\",\n",
    "                \"format\": \"gff3\",\n",
    "                \"type\": \"annotation\",\n",
    "                \"displayMode\": \"expanded\",\n",
    "                \"height\":120,\n",
    "                \"indexed\": False }\n",
    "]\n",
    "colors=['orange','green','gray']\n",
    "i=0\n",
    "for b in bams:\n",
    "    d = {\"name\": b,\n",
    "        \"url\":url+bams[b],\n",
    "        \"type\": \"alignment\",\n",
    "         #\"displayMode\":\"SQUISHED\",\n",
    "         \"height\":800,\n",
    "         \"removable\":True,\n",
    "         #\"color\":colors[i],\n",
    "        \"indexed\": True }\n",
    "    track_list.append(d)\n",
    "    i+=1\n",
    "    \n",
    "genome = IGV.create_genome(\n",
    "    name=\"Hmed\",   \n",
    "    fasta_url=url+'data/refs/Hvol_Chr_NC_013967.1.fasta',\n",
    "    index_url=url+ 'data/refs/Hvol_Chr_NC_013967.1.fasta.fai',\n",
    "    tracks=track_list\n",
    ")\n",
    "\n",
    "#create the widget\n",
    "igv = IGV(genome=genome)\n",
    "\n",
    "\n",
    "display(igv)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7306054d",
   "metadata": {},
   "source": [
    "### What have you found?\n",
    "\n",
    "At this point, you should have identified two regions in each genome where recombination has occurred. There are lots of questions to ask here. For example - what is shared between these genes? What is the function of the genes? Are these genes still functional? \n",
    "\n",
    "You need to have a think about this going forwards."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d3bf6be",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58d506f4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
